{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5492b5-eecd-4909-ae3b-17c78b193285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.utils.data_utils import load_from_disk\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import train_Delaney\n",
    "\n",
    "dataset_file= \"delaney-processed.csv\"\n",
    "\n",
    "dataset = load_from_disk(dataset_file)\n",
    "\n",
    "featurizer = dc.feat.CircularFingerprint(size=1024)\n",
    "loader = dc.data.CSVLoader(tasks=[\"measured log solubility in mols per litre\"], smiles_field=\"smiles\", featurizer=featurizer)\n",
    "dataset = loader.featurize(dataset_file)\n",
    "\n",
    "Num_layer = 2\n",
    "dim = [32,64]\n",
    "\n",
    "#####  Data splitting into test:train = 2:8\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset, frac_train= .8, frac_valid = 0, frac_test= .2)\n",
    "\n",
    "##### Data Normalization (zero mean, unit variance)\n",
    "transformers = [dc.trans.NormalizationTransformer(transform_y=True, dataset=train_dataset)]\n",
    "\n",
    "for dataset in [train_dataset, test_dataset]:\n",
    "    for transformer in transformers:\n",
    "        dataset = transformer.transform(dataset)\n",
    "\n",
    "\n",
    "model, history = train_Delaney.train((train_dataset,test_dataset), Num_layer, dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc70952-cd41-4d8a-b486-a349cf473b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(test_dataset.X, test_dataset.y, verbose=2)\n",
    "print(\"best RMSE: %f\\nbest r2value: %f\" % (mse, 1-(mse/test_dataset.y.var())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6197a20-2013-4998-b92f-2151a9f4f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21cb09-ca97-4381-92c8-9fc9fdf64016",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Optimization plot of the FCNN with best set of parameters, and the best MSE value. \n",
    "##### Model_8 (2 hidden layers, 256 neurons each) seems to be the best model\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "def plot_history(history):\n",
    "\n",
    "  plt.figure(figsize=(8,12))\n",
    "\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,2])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "loss, mae, mse = model.evaluate(test_dataset.X, test_dataset.y, verbose=2)\n",
    "print(\"best RMSE: %f\\nbest r2value: %f\" % (mse, 1-(mse/test_dataset.y.var())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea0d44-8dc0-4d2f-b699-a0b6f9dbf385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
